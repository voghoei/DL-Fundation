{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run this from a normal command line\n",
    "pip install -U pip setuptools wheel\n",
    "\n",
    "pip install -U spacy\n",
    "\n",
    "python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is\n",
      "[ 0.8564443   0.4766266   0.8617331  -0.23298171 -0.43807706 -0.4832915\n",
      " -0.6782286  -0.6165445  -0.4114128  -0.46499562 -0.3495959  -0.2839256\n",
      "  0.28612393 -0.3503814  -0.36538255  1.0177352   0.21290846 -0.27140924\n",
      "  0.18076144 -0.40929875 -0.49892646 -0.5546873  -0.42378613  0.10939625\n",
      " -1.0392536   0.37995195  0.48060113  0.58837724 -0.1122672   1.7131376\n",
      " -0.13288209 -0.47156957 -0.1330317  -0.8155582   1.3928298  -0.27894223\n",
      "  0.44829082  0.32962656  0.48554176  1.5739237  -0.57067466 -0.88091177\n",
      " -0.10498527  1.8027776   0.26098835  0.41870505 -0.36758125  1.0122786\n",
      "  0.0349464   0.03160805  0.48975492 -0.3618569  -0.31644097 -0.54032993\n",
      "  1.2121011  -0.6231067   0.46006358 -0.54157126  0.36904725  0.3193823\n",
      " -0.8758935  -0.27929828 -0.09163581 -0.8307545  -0.63962394 -0.41370696\n",
      "  0.21290371 -0.63957536  0.01796842 -0.5415094  -0.13805059 -0.7935434\n",
      "  0.6140887  -0.33843002 -0.6934269  -0.9170069  -0.9540802   0.25677288\n",
      " -0.2514622  -0.67673814  0.6296971   0.8888931  -0.31606063  0.24339122\n",
      " -1.0111456  -0.23862018 -0.00503597 -0.20325519 -0.80539644 -0.14348447\n",
      " -0.3129095   1.3698952   0.58666265  0.5252736  -0.99657714 -0.19642189]\n"
     ]
    }
   ],
   "source": [
    "# process a sentence using the model\n",
    "doc = nlp(\"This is some text that I am processing with Spacy\")\n",
    "# It's that simple - all of the vectors and words are assigned after this point\n",
    "\n",
    "# Get the mean vector for the entire sentence (useful for sentence classification etc.)\n",
    "print(doc[1])\n",
    "\n",
    "# Get the vector for 'text':\n",
    "print(doc[3].vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14, size=100, alpha=0.025)\n",
      "['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec', 'second', 'yet', 'another', 'one', 'more', 'and', 'final']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "# summarize the loaded model\n",
    "print(model)\n",
    "# summarize vocabulary\n",
    "words = list(model.wv.vocab)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0032883  -0.00390584 -0.00421317  0.002119    0.00463947 -0.00278183\n",
      "  0.00127867 -0.00226567  0.00120829 -0.00331233 -0.00152873 -0.00201674\n",
      " -0.00368217 -0.00224742 -0.00196707  0.00386393  0.00201424  0.0034398\n",
      "  0.00082466 -0.00438115  0.00046155 -0.00417112  0.00144746  0.00061535\n",
      " -0.00155151  0.00017241  0.00333034  0.00191787  0.00416419 -0.00263528\n",
      " -0.00484607  0.00412971  0.00423113 -0.00056955 -0.00252749  0.00269066\n",
      " -0.00383877  0.00436052 -0.00493478 -0.00040463 -0.00384861 -0.00224854\n",
      "  0.00149034 -0.00023116 -0.0003864   0.00480267  0.00191557 -0.00303456\n",
      " -0.00043126 -0.00348976  0.00465063  0.00329368  0.00147671  0.00325747\n",
      "  0.00044374 -0.00023383 -0.00159821 -0.00138612 -0.00405744  0.00025413\n",
      " -0.00193896 -0.00208419  0.00148093  0.00411121  0.00018821  0.00201775\n",
      " -0.00234678 -0.00043392 -0.00311013 -0.00308172  0.00319079  0.00220969\n",
      "  0.00143475 -0.00358833 -0.00405694 -0.00432123 -0.00383134 -0.00329075\n",
      "  0.00071055  0.00303915 -0.00015106 -0.00459208 -0.00206584  0.00440273\n",
      "  0.00019415  0.00352238 -0.00200452  0.00067658 -0.00099394  0.00314972\n",
      " -0.00134207  0.00484961  0.00340173  0.00017365 -0.00369487  0.00074851\n",
      " -0.00039595 -0.00269852 -0.00060837  0.00335775]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voghoei\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# access vector for one word\n",
    "print(model['this'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=14, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "# save model\n",
    "model.save('model.bin')\n",
    "# load model\n",
    "new_model = Word2Vec.load('model.bin')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voghoei\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "# define training data\n",
    "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
    "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
    "\t\t\t['yet', 'another', 'sentence'],\n",
    "\t\t\t['one', 'more', 'sentence'],\n",
    "\t\t\t['and', 'the', 'final', 'sentence']]\n",
    "# train model\n",
    "model = Word2Vec(sentences, min_count=1)\n",
    "# fit a 2d PCA model to the vectors\n",
    "X = model[model.wv.vocab]\n",
    "pca = PCA(n_components=2)\n",
    "result = pca.fit_transform(X)\n",
    "# create a scatter plot of the projection\n",
    "pyplot.scatter(result[:, 0], result[:, 1])\n",
    "words = list(model.wv.vocab)\n",
    "for i, word in enumerate(words):\n",
    "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load Google’s Word2Vec Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------------------------------------] 1.4% 23.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=-------------------------------------------------] 3.6% 59.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------------------------------------] 5.7% 95.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===-----------------------------------------------] 7.9% 131.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====---------------------------------------------] 11.5% 191.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======-------------------------------------------] 14.8% 246.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========------------------------------------------] 17.0% 283.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========-----------------------------------------] 19.2% 319.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========----------------------------------------] 22.0% 365.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============--------------------------------------] 25.8% 429.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============------------------------------------] 29.9% 497.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================----------------------------------] 33.4% 555.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-------------------------------] 39.1% 650.7/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================-----------------------------] 42.6% 708.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================---------------------------] 46.4% 771.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================-------------------------] 50.4% 838.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================-----------------------] 54.2% 901.9/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[============================----------------------] 57.6% 957.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================--------------------] 61.4% 1021.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================------------------] 65.5% 1089.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================----------------] 68.7% 1143.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================================--------------] 72.6% 1207.0/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[======================================------------] 76.6% 1274.5/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================----------] 80.1% 1331.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================---------] 83.7% 1392.4/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========================================-------] 87.5% 1455.6/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================-----] 91.2% 1517.1/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================--] 96.8% 1609.8/1662.8MB downloaded"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02978516, 0.00860596], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_king = wv['king']\n",
    "vec_king[1:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'cameroon' does not appear in this model\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    vec_cameroon = wv['cameroon']\n",
    "except KeyError:\n",
    "    print(\"The word 'cameroon' does not appear in this model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = wv.similarity('woman', 'man')\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7118192911148071)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the google word2vec model\n",
    "filename = r'C:\\Users\\voghoei\\Python\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.76640123"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity = model.similarity('woman', 'man')\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2813\n"
     ]
    }
   ],
   "source": [
    "#conda install -c conda-forge pyemd\n",
    "sentence_obama = \"Obama speaks to the media in Illinois\".lower().split()\n",
    "sentence_president = \"The president greets the press in Chicago\".lower().split()\n",
    "\n",
    "similarity1 = model.wmdistance(sentence_obama, sentence_president)\n",
    "print(f\"{similarity1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "distance = model.distance(\"media\", \"media\")\n",
    "print(f\"{distance:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5984\n"
     ]
    }
   ],
   "source": [
    "similarity2 = model.n_similarity(['sushi', 'shop'], ['japanese', 'restaurant'])\n",
    "print(f\"{similarity2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model['computer']  # numpy vector of a word\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\voghoei\\.conda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = model.wv.get_vector('office')\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Stanford’s GloVe Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file =  r'C:\\Users\\voghoei\\Python\\glove.6B\\glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.7698541283607483)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
